{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group 5\n",
    "## Team members:\n",
    "- Jianting Liu(8950907)\n",
    "- David (8999846) \n",
    "- Marieth (9016702)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Canadian Housing Market Analysis: 20-Year Review\n",
    "\n",
    "## Use Case Summary & Hypothesis Testing\n",
    "\n",
    "The analysis examines the relationship between housing prices, income, and population in Canada over a 20-year period. By incorporating population data alongside existing housing prices and income metrics, we can better understand the demographic pressures on housing affordability.\n",
    "\n",
    "### Hypothesis\n",
    "\n",
    "**Null Hypothesis (H0):**  \n",
    "There is no significant correlation between population growth and housing price increases when controlling for income changes.\n",
    "\n",
    "**Alternative Hypothesis (H1):**  \n",
    "Population growth has a significant positive correlation with housing price increases, even after controlling for income changes.\n",
    "\n",
    "This enhanced analysis will help determine whether population growth is a significant driver of housing prices beyond what can be explained by income changes alone.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Megeing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class IncomeDataProcessor:\n",
    "    \"\"\"\n",
    "    A class to process income and house price data.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, income_data_path, original_data_path):\n",
    "        \"\"\"\n",
    "        Initializes the class with the given data paths.\n",
    "\n",
    "        Args:\n",
    "            income_data_path (str): Path to the income data CSV file.\n",
    "            original_data_path (str): Path to the original data Excel file.\n",
    "        \"\"\"\n",
    "        self.income_data = pd.read_csv(income_data_path)\n",
    "        self.original_data = pd.read_excel(original_data_path)\n",
    "\n",
    "    def clean_data(self):\n",
    "        \"\"\"\n",
    "        Cleans the income data by removing currency symbols and converting to numeric.\n",
    "        \"\"\"\n",
    "        self.income_data['Median income'] = self.income_data['Median income'].str.replace('$', '').str.replace(',', '').astype(float)\n",
    "\n",
    "    def convert_to_monthly(self):\n",
    "        \"\"\"\n",
    "        Converts annual income to monthly income and creates a new DataFrame.\n",
    "        \"\"\"\n",
    "        new_rows = []\n",
    "        \n",
    "        for index, row in self.income_data.iterrows():\n",
    "            year = row[\"Reference year\"]\n",
    "            median_income = row[\"Median income\"] / 12  # Convert to monthly income\n",
    "            \n",
    "            for month in range(1, 13):\n",
    "                date_str = f\"{year}-{month:02d}-01\"\n",
    "                date = pd.to_datetime(date_str, format='%Y-%m-%d')\n",
    "                \n",
    "                new_row = {\n",
    "                    \"Date\": date,\n",
    "                    \"Median income\": median_income,\n",
    "                    \"Count of families\": row[\"Count of families\"],\n",
    "                    \"Family type\": row[\"Family type\"],\n",
    "                    \"Geography\": row[\"Geography\"],\n",
    "                    \"Selected income concept\": row[\"Selected income concept\"]\n",
    "                }\n",
    "                new_rows.append(new_row)\n",
    "        \n",
    "        self.monthly_data = pd.DataFrame(new_rows)\n",
    "        \n",
    "        return self.monthly_data\n",
    "\n",
    "    def merge_data(self):\n",
    "        \"\"\"\n",
    "        Merges the income data with the original data based on the 'Date' column.\n",
    "        \"\"\"\n",
    "        self.monthly_data['Date'] = pd.to_datetime(self.monthly_data['Date'], format='%Y-%m-%d')\n",
    "        self.merged_data = pd.merge(self.original_data, self.monthly_data[['Date', 'Median income']], on='Date', how='left')\n",
    "        # Filter data from 2005 to 2022\n",
    "        self.merged_data = self.merged_data[(self.merged_data['Date'].dt.year >= 2005) & \n",
    "                                           (self.merged_data['Date'].dt.year <= 2022)]\n",
    "        return self.merged_data\n",
    "    \n",
    "    def apply_kmeans_clustering(self, n_clusters=3):\n",
    "        \"\"\"\n",
    "        Applies K-Means clustering on 'Median income' and 'Apartment_unit' columns.\n",
    "        \n",
    "        Args:\n",
    "            n_clusters (int): Number of clusters to form.\n",
    "        \n",
    "        Returns:\n",
    "            DataFrame with a new 'Cluster' column.\n",
    "        \"\"\"\n",
    "        clustering_data = self.merged_data[['Median income', 'Apartment_unit']].dropna()\n",
    "        \n",
    "        # Data scaling\n",
    "        scaler = StandardScaler()\n",
    "        scaled_data = scaler.fit_transform(clustering_data)\n",
    "\n",
    "        # K-Means clustering\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "        clustering_data['Cluster'] = kmeans.fit_predict(scaled_data)\n",
    "        \n",
    "        # Plot clusters\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.scatterplot(\n",
    "            x='Median income', y='Apartment_unit', \n",
    "            hue='Cluster', data=clustering_data, palette='viridis'\n",
    "        )\n",
    "        plt.title(\"Clustering of Income and Apartment Prices\")\n",
    "        plt.show()\n",
    "\n",
    "        return clustering_data\n",
    "\n",
    "    def save_data(self, output_path):\n",
    "        \"\"\"\n",
    "        Saves the merged data to a CSV file.\n",
    "        \"\"\"\n",
    "        self.merged_data.to_csv(output_path)\n",
    "    \n",
    "    def exploratory_data_analysis(self):\n",
    "        \"\"\"\n",
    "        Performs exploratory data analysis, including:\n",
    "            - Visualizing the relationship between income and house price\n",
    "            - Histogram and box plot of income and apartment prices\n",
    "        \"\"\"\n",
    "\n",
    "        # Histogramas de Median income y Apartment_unit\n",
    "        plt.figure(figsize=(10, 10))\n",
    "\n",
    "        # Histogram of Median income\n",
    "        plt.subplot(2, 1, 1)\n",
    "        sns.histplot(self.merged_data['Median income'].dropna(), kde=True)\n",
    "        plt.title(\"Distribution of Median Income\")\n",
    "\n",
    "        # Histogram of Apartment_unit prices\n",
    "        plt.subplot(2, 1, 2)\n",
    "        sns.histplot(self.merged_data['Apartment_unit'].dropna(), kde=True)\n",
    "        plt.title(\"Distribution of Apartment Prices\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Boxplots de Median income y Apartment_unit\n",
    "        plt.figure(figsize=(10, 10))\n",
    "\n",
    "        # Box plot of Median income\n",
    "        plt.subplot(2, 1, 1)\n",
    "        sns.boxplot(x=self.merged_data['Median income'].dropna())\n",
    "        plt.title(\"Box Plot of Median Income\")\n",
    "\n",
    "        # Box plot of Apartment_unit prices\n",
    "        plt.subplot(2, 1, 2)\n",
    "        sns.boxplot(x=self.merged_data['Apartment_unit'].dropna())\n",
    "        plt.title(\"Box Plot of Apartment Prices\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Scatter plot of income vs apartment prices\n",
    "        sns.scatterplot(x='Median income', y='Apartment_unit', data=self.merged_data)\n",
    "        plt.title(\"Income vs Apartment Prices\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# Example usage\n",
    "processor = IncomeDataProcessor('incomedata.csv', 'News_release_chart_data_August_2024.xlsx')\n",
    "processor.clean_data()\n",
    "processor.convert_to_monthly()\n",
    "data = processor.merge_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We download the population data from the website and convert it to monthly data.\n",
    "data source:https://www150.statcan.gc.ca/t1/tbl1/en/tv.action?pid=1710000901&cubeTimeFrame.startMonth=01&cubeTimeFrame.startYear=2005&cubeTimeFrame.endMonth=07&cubeTimeFrame.endYear=2024&referencePeriods=20050101%2C20240701"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Composite  One_storey  Two_storey  Townhouse  Apartment_unit  \\\n",
      "0  2005-01-01     239800      207700      302900     201700          172000   \n",
      "1  2005-02-01     240500      208400      303300     202300          173000   \n",
      "2  2005-03-01     241300      209200      304300     202900          173900   \n",
      "3  2005-04-01     242000      210100      304800     203300          174600   \n",
      "4  2005-05-01     242600      210600      305400     203700          175400   \n",
      "\n",
      "   Median income    Population  \n",
      "0         4487.5  1.069167e+07  \n",
      "1         4487.5  1.069167e+07  \n",
      "2         4487.5  1.069167e+07  \n",
      "3         4487.5  1.071352e+07  \n",
      "4         4487.5  1.071352e+07  \n"
     ]
    }
   ],
   "source": [
    "def convert_excel_format(input_file, output_file, merge_file):\n",
    "    # Read Excel file\n",
    "    df = pd.read_excel(input_file)\n",
    "    \n",
    "    # Get column names and data values\n",
    "    dates = df.columns.tolist()[1:]  # Skip first column\n",
    "    values = df.iloc[0, 1:].tolist()  # Skip first column\n",
    "    \n",
    "    # Create new DataFrame\n",
    "    new_df = pd.DataFrame({\n",
    "        'Date': dates,\n",
    "        'Population': values\n",
    "    })\n",
    "    \n",
    "    # Remove rows containing 'Date' or 'Population'\n",
    "    new_df = new_df[~new_df['Date'].isin(['Date'])]\n",
    "    \n",
    "    # Convert quarterly data to date format\n",
    "    new_df['Date'] = new_df['Date'].str.replace('Q', '').str.split().apply(\n",
    "        lambda x: pd.to_datetime(f\"{x[1]}-{int(x[0])*3-2}-01\")\n",
    "    )\n",
    "    \n",
    "    # Create empty lists for monthly data\n",
    "    monthly_dates = []\n",
    "    monthly_populations = []\n",
    "    \n",
    "    # Process each quarterly data\n",
    "    for idx, row in new_df.iterrows():\n",
    "        quarter_start = row['Date']\n",
    "        population = row['Population']\n",
    "        \n",
    "        # Create data for three months in each quarter\n",
    "        for month in range(3):\n",
    "            monthly_date = quarter_start + pd.DateOffset(months=month)\n",
    "            monthly_population = population / 3  # Distribute quarterly population evenly across months\n",
    "            \n",
    "            monthly_dates.append(monthly_date)\n",
    "            monthly_populations.append(monthly_population)\n",
    "    \n",
    "    # Create new monthly DataFrame\n",
    "    monthly_df = pd.DataFrame({\n",
    "        'Date': monthly_dates,\n",
    "        'Population': monthly_populations\n",
    "    })\n",
    "    \n",
    "    # Sort by date\n",
    "    monthly_df = monthly_df.sort_values('Date').reset_index(drop=True)\n",
    "    \n",
    "    # Format date column to 'YYYY-MM-DD'\n",
    "    monthly_df['Date'] = monthly_df['Date'].dt.strftime('%Y-%m-%d')\n",
    "    \n",
    "    # Read CSV file to merge\n",
    "    merge_df = pd.read_csv(merge_file)\n",
    "    \n",
    "    # Ensure Date columns have consistent format in both DataFrames\n",
    "    merge_df['Date'] = pd.to_datetime(merge_df['Date']).dt.strftime('%Y-%m-%d')\n",
    "    \n",
    "    # Merge data\n",
    "    final_df = pd.merge(merge_df, monthly_df, on='Date', how='left')\n",
    "    \n",
    "    # Save final result\n",
    "    final_df.to_excel(output_file, index=False)\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "# Usage example\n",
    "input_file = 'population.xlsx'\n",
    "merge_file = 'mergeddata.csv'\n",
    "output_file = 'final_merged_data.xlsx'\n",
    "\n",
    "result = convert_excel_format(input_file, output_file, merge_file)\n",
    "print(result.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data preprocessing...\n",
      "Dropping columns with missing values ratio above 0.5: []\n",
      "Dropping columns with variance less than 0.01: []\n",
      "         Date  Composite  One_storey  Two_storey  Townhouse  Apartment_unit  \\\n",
      "0  2005-01-01     239800      207700      302900     201700          172000   \n",
      "1  2005-02-01     240500      208400      303300     202300          173000   \n",
      "2  2005-03-01     241300      209200      304300     202900          173900   \n",
      "3  2005-04-01     242000      210100      304800     203300          174600   \n",
      "4  2005-05-01     242600      210600      305400     203700          175400   \n",
      "\n",
      "   Median income    Population  \n",
      "0         4487.5  1.069167e+07  \n",
      "1         4487.5  1.069167e+07  \n",
      "2         4487.5  1.069167e+07  \n",
      "3         4487.5  1.071352e+07  \n",
      "4         4487.5  1.071352e+07  \n",
      "PCA applied, created 2 components\n",
      "         Date  Composite  One_storey  Two_storey  Townhouse  Apartment_unit  \\\n",
      "0  2005-01-01     239800      207700      302900     201700          172000   \n",
      "1  2005-02-01     240500      208400      303300     202300          173000   \n",
      "2  2005-03-01     241300      209200      304300     202900          173900   \n",
      "3  2005-04-01     242000      210100      304800     203300          174600   \n",
      "4  2005-05-01     242600      210600      305400     203700          175400   \n",
      "\n",
      "   Median income    Population     PCA_1     PCA_2  \n",
      "0         4487.5  1.069167e+07 -3.859664 -0.693530  \n",
      "1         4487.5  1.069167e+07 -3.849140 -0.698686  \n",
      "2         4487.5  1.069167e+07 -3.837183 -0.704759  \n",
      "3         4487.5  1.071352e+07 -3.815109 -0.700924  \n",
      "4         4487.5  1.071352e+07 -3.806441 -0.705150  \n",
      "Selected important features based on Random Forest: ['Population', 'Median income', 'Date', 'Townhouse', 'One_storey', 'PCA_1']\n",
      "Selected features using RFE: ['Population', 'Median income', 'Townhouse', 'One_storey', 'PCA_1']\n",
      "final\n",
      "     Population  Median income  Townhouse  One_storey     PCA_1        Date  \\\n",
      "0  1.069167e+07         4487.5     201700      207700 -3.859664  2005-01-01   \n",
      "1  1.069167e+07         4487.5     202300      208400 -3.849140  2005-02-01   \n",
      "2  1.069167e+07         4487.5     202900      209200 -3.837183  2005-03-01   \n",
      "3  1.071352e+07         4487.5     203300      210100 -3.815109  2005-04-01   \n",
      "4  1.071352e+07         4487.5     203700      210600 -3.806441  2005-05-01   \n",
      "\n",
      "   Apartment_unit  \n",
      "0          172000  \n",
      "1          173000  \n",
      "2          173900  \n",
      "3          174600  \n",
      "4          175400  \n",
      "final fnal\n",
      "     Population  Median income  Townhouse  One_storey     PCA_1        Date  \\\n",
      "0  1.069167e+07         4487.5     201700      207700 -3.859664  2005-01-01   \n",
      "1  1.069167e+07         4487.5     202300      208400 -3.849140  2005-02-01   \n",
      "2  1.069167e+07         4487.5     202900      209200 -3.837183  2005-03-01   \n",
      "3  1.071352e+07         4487.5     203300      210100 -3.815109  2005-04-01   \n",
      "4  1.071352e+07         4487.5     203700      210600 -3.806441  2005-05-01   \n",
      "\n",
      "   Apartment_unit  \n",
      "0          172000  \n",
      "1          173000  \n",
      "2          173900  \n",
      "3          174600  \n",
      "4          175400  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/feature_selection/_rfe.py:291: UserWarning: Found n_features_to_select=8 > n_features=5. There will be no feature selection and all features will be kept.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preprocessing completed and saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class DataPreprocessor:\n",
    "    def __init__(self, file_path):\n",
    "        self.data = pd.read_excel(file_path)\n",
    "    \n",
    "    def missing_values_ratio(self, threshold=0.5):\n",
    "        \"\"\"\n",
    "        Removes columns with a missing values ratio above the specified threshold.\n",
    "        \"\"\"\n",
    "        missing_ratio = self.data.isnull().mean()\n",
    "        cols_to_drop = missing_ratio[missing_ratio > threshold].index\n",
    "        print(f\"Dropping columns with missing values ratio above {threshold}: {list(cols_to_drop)}\")\n",
    "        #self.data.drop(columns=cols_to_drop, inplace=True)\n",
    "    \n",
    "    def low_variance_filter(self, threshold=0.01):\n",
    "        \"\"\"\n",
    "        Removes columns with variance below a specified threshold.\n",
    "        \"\"\"\n",
    "        numeric_data = self.data.select_dtypes(include=[np.number])\n",
    "        variance = numeric_data.var()\n",
    "        cols_to_drop = variance[variance < threshold].index\n",
    "        print(f\"Dropping columns with variance less than {threshold}: {list(cols_to_drop)}\")\n",
    "        #self.data.drop(columns=cols_to_drop, inplace=True)\n",
    "    \n",
    "    \n",
    "    def high_correlation_filter(self, threshold=0.9):\n",
    "        \"\"\"\n",
    "        Removes one of two columns that have a correlation higher than the threshold.\n",
    "        \"\"\"\n",
    "        # Select only numeric columns\n",
    "        numeric_data = self.data.select_dtypes(include=[np.number])\n",
    "        \n",
    "        # Temporarily fill null values with the mean to avoid errors in the correlation calculation\n",
    "        numeric_data = numeric_data.fillna(numeric_data.mean())\n",
    "        \n",
    "        # Calculate the absolute correlation matrix\n",
    "        corr_matrix = numeric_data.corr().abs()\n",
    "        \n",
    "        # Select only the upper half of the correlation matrix to avoid duplicates\n",
    "        upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "        \n",
    "        # Find columns with correlation higher than the threshold\n",
    "        cols_to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > threshold)]\n",
    "        \n",
    "        print(f\"Dropping columns with correlation higher than {threshold}: {list(cols_to_drop)}\")\n",
    "        \n",
    "        # Drop the selected columns from the DataFrame\n",
    "        self.data.drop(columns=cols_to_drop, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "    def apply_pca(self, n_components=2):\n",
    "        \"\"\"\n",
    "        Applies Principal Component Analysis to reduce dimensions.\n",
    "        \"\"\"\n",
    "        print(self.data.head())\n",
    "        scaler = StandardScaler()\n",
    "        numeric_data = self.data.select_dtypes(include=[np.number]).dropna()\n",
    "        scaled_data = scaler.fit_transform(numeric_data)\n",
    "        \n",
    "        pca = PCA(n_components=n_components)\n",
    "        pca_data = pca.fit_transform(scaled_data)\n",
    "        \n",
    "        for i in range(n_components):\n",
    "            self.data[f'PCA_{i+1}'] = pca_data[:, i]\n",
    "        print(f\"PCA applied, created {n_components} components\")\n",
    "        print(self.data.head())\n",
    "    \n",
    "    def feature_selection_random_forest(self, target_column):\n",
    "        \"\"\"\n",
    "        Selects important features based on Random Forest importance.\n",
    "        \"\"\"\n",
    "        features = self.data.drop(columns=[target_column]).select_dtypes(include=[np.number])\n",
    "        target = self.data[target_column].dropna()\n",
    "        \n",
    "        model = RandomForestRegressor(random_state=0)\n",
    "        model.fit(features, target)\n",
    "        \n",
    "        importances = model.feature_importances_\n",
    "        important_features = features.columns[importances > np.mean(importances)]\n",
    "\n",
    "        essential_columns = ['Date', 'Median income', 'Population']\n",
    "        important_features = list(set(important_features) | set(essential_columns))\n",
    "        print(f\"Selected important features based on Random Forest: {list(important_features)}\")\n",
    "        \n",
    "        self.data = self.data[important_features + [target_column]]\n",
    "    \n",
    "    def backward_feature_elimination(self, target_column, n_features=8):\n",
    "        \"\"\"\n",
    "        Applies Recursive Feature Elimination to select top features.\n",
    "        \"\"\"\n",
    "        features = self.data.drop(columns=[target_column]).select_dtypes(include=[np.number])\n",
    "        target = self.data[target_column].dropna()\n",
    "        \n",
    "        model = RandomForestRegressor(random_state=0)\n",
    "        selector = RFE(model, n_features_to_select=n_features)\n",
    "        selector.fit(features, target)\n",
    "        \n",
    "        selected_features = features.columns[selector.support_]\n",
    "        print(f\"Selected features using RFE: {list(selected_features)}\")\n",
    "        \n",
    "        selected_features = list(selected_features) + ['Date']\n",
    "        self.data = self.data[selected_features + [target_column]]\n",
    "        print(\"final\")\n",
    "        print(self.data.head())\n",
    "    \n",
    "    def save_cleaned_data(self, output_path):\n",
    "        \"\"\"\n",
    "        Saves the cleaned data to a new Excel file.\n",
    "        \"\"\"\n",
    "        print(\"final fnal\")\n",
    "        print(self.data.head())\n",
    "        self.data.to_excel(output_path, index=False)\n",
    "    \n",
    "    def preprocess_all(self, target_column, output_path):\n",
    "        \"\"\"\n",
    "        Executes the full preprocessing pipeline.\n",
    "        \"\"\"\n",
    "        print(\"Starting data preprocessing...\")\n",
    "        self.missing_values_ratio()\n",
    "        self.low_variance_filter()\n",
    "        #self.high_correlation_filter()\n",
    "        self.apply_pca()\n",
    "        self.feature_selection_random_forest(target_column)\n",
    "        self.backward_feature_elimination(target_column)\n",
    "        self.save_cleaned_data(output_path)\n",
    "        print(\"Data preprocessing completed and saved.\")\n",
    "\n",
    "# Usage Example\n",
    "input_file = 'final_merged_data.xlsx'\n",
    "output_file = 'cleaned_data.xlsx'\n",
    "target_column = 'Apartment_unit'  # Example target column for feature selection\n",
    "\n",
    "preprocessor = DataPreprocessor(input_file)\n",
    "preprocessor.preprocess_all(target_column, output_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
